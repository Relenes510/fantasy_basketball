{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f639b832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2026-01-11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# email\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "categories = ['PTS', 'AST', 'REB', 'PR', 'PA', 'RA', 'PRA', 'TPM', 'STL', 'BLK', 'STL_BLK']\n",
    "con = duckdb.connect(database=\":memory:\")\n",
    "\n",
    "cwd = os.path.abspath(os.getcwd()).replace(\"\\\\\", \"/\")\n",
    "if cwd.startswith(\"C:/Users/Rodolfo/\"):\n",
    "    RUN_LOCATION = \"local\"\n",
    "else:\n",
    "    RUN_LOCATION = \"cloud\"\n",
    "time_offset = {\"local\": 3, \"cloud\": -5}\n",
    "now = str((datetime.now() + timedelta(hours=time_offset[RUN_LOCATION]) + timedelta(hours=-3)).date())\n",
    "print(f\"Today's date:\", now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31db1bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./common_utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ede7d",
   "metadata": {},
   "source": [
    "# Initial Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde5d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email(model, error):\n",
    "    \n",
    "    # Email details\n",
    "    sender_email = \"rodolfoe7157@gmail.com\"\n",
    "    receiver_email = \"rodolfoe7157@gmail.com\"\n",
    "    password = \"cqgu bfey cnyx sfue\"  # See note below\n",
    "\n",
    "    subject = \"NBA create_Predictions error\"\n",
    "    body = f\"Model: {model}_model\\nERROR: {error}\"\n",
    "\n",
    "    # Create message\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = receiver_email\n",
    "    msg['Subject'] = subject\n",
    "    msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "    # Connect to Gmail SMTP server and send\n",
    "    with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:\n",
    "        server.login(sender_email, password)\n",
    "        server.send_message(msg)\n",
    "\n",
    "    print(\"Email sent successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df2cc012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(file_name):\n",
    "    df = pd.DataFrame()\n",
    "    for i in [2021, 2022, 2023, 2024, 2025]:\n",
    "        df_temp = pd.read_csv(f\"../tables/{i}/{file_name}.csv\")\n",
    "        df_temp['Season'] = i\n",
    "        df = pd.concat([df, df_temp])\n",
    "        \n",
    "    if 'Date' in df.columns:\n",
    "        df['Date'] = pd.to_datetime(df.Date)\n",
    "    if file_name == \"season_gamelogs\":\n",
    "        df = df[~df[['Date', 'Team', 'Player']].duplicated(keep='last')]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "148cf688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_df():\n",
    "    \n",
    "    # Load dfs\n",
    "    df = load_df('parlay_stats')\n",
    "    df2 = load_df('nba_schedule')\n",
    "    df3 = load_df('season_gamelogs')\n",
    "    df4 = load_df('injuries')\n",
    "    df5 = load_df('plyr_pos_xref')\n",
    "    df6 = load_df('daily_lineups')\n",
    "    gmlog_cols = ['game_id', 'Player', 'MP', 'PF']\n",
    "    df7 = load_df('h1_season_gamelogs')[gmlog_cols].rename(columns={\"MP\": \"MP_h1\", \"PF\": \"PF_h1\"})\n",
    "    df8 = load_df('h2_season_gamelogs')[gmlog_cols].rename(columns={\"MP\": \"MP_h2\", \"PF\": \"PF_h2\"})\n",
    "    df9 = load_df('q1_season_gamelogs')[gmlog_cols].rename(columns={\"MP\": \"MP_q1\", \"PF\": \"PF_q1\"})\n",
    "    df10 = load_df('q2_season_gamelogs')[gmlog_cols].rename(columns={\"MP\": \"MP_q2\", \"PF\": \"PF_q2\"})\n",
    "    df11 = load_df('q3_season_gamelogs')[gmlog_cols].rename(columns={\"MP\": \"MP_q3\", \"PF\": \"PF_q3\"})\n",
    "    df12 = load_df('q4_season_gamelogs')[gmlog_cols].rename(columns={\"MP\": \"MP_q4\", \"PF\": \"PF_q4\"})\n",
    "\n",
    "    df3 = df3.rename(columns={\"3PM\": \"TPM\", \"3PA\": \"TPA\", \"3P%\": \"TP%\", \"TRB\": \"REB\"}).drop(['Pos', 'Opp'], axis=1)\n",
    "    df3['PR'] = df3.PTS + df3.REB \n",
    "    df3['PA'] = df3.PTS + df3.AST\n",
    "    df3['RA'] = df3.REB + df3.AST\n",
    "    df3['PRA'] = df3.PTS + df3.REB + df3.AST\n",
    "    df3['STL_BLK'] = df3.STL + df3.BLK\n",
    "    df = df.merge(df3, on=['Season', 'Date', 'Team', 'Player'], how='left')\n",
    "\n",
    "    df_mtch = df2[['Season', 'Date', 'AwayABV', 'HomeABV', 'AwayPTS', 'HomePTS', 'AwayB2B', 'HomeB2B', 'is_OT', 'cup_gm', 'pstszn_gm']]\n",
    "    df_mtch['Team_type'] = 'Away'\n",
    "    df_mtch = df_mtch.rename(columns={\"AwayABV\": \"Team\", \"HomeABV\": \"Opp\", \"AwayB2B\": \"B2B\"})[['Season', 'Date', 'Team', 'AwayPTS', 'HomePTS', 'Opp', 'B2B', 'is_OT', 'cup_gm', 'pstszn_gm', 'Team_type']]\n",
    "    df_mtch2 = df_mtch.copy().rename(columns={\"Team\": \"Opp\", \"Opp\": \"Team\", \"HomeB2B\": \"B2B\"})[['Season', 'Date', 'Team', 'AwayPTS', 'HomePTS', 'Opp', 'B2B', 'is_OT', 'cup_gm', 'pstszn_gm']]\n",
    "    df_mtch2['Team_type'] = 'Home'\n",
    "    df_mtch = pd.concat([df_mtch, df_mtch2])\n",
    "    df_mtch = df_mtch[['Season', 'Date', 'Team', 'Team_type', 'AwayPTS', 'HomePTS', 'is_OT', 'cup_gm', 'pstszn_gm']]\n",
    "    df_mtch = df_mtch.sort_values([\"Team\", \"Date\"])\n",
    "    df_mtch['team_game_num'] = df_mtch.groupby([\"Team\", \"Season\"]).cumcount() + 1\n",
    "    df_mtch['Spread'] = np.where(df_mtch.Team_type == 'Home', df_mtch.AwayPTS - df_mtch.HomePTS, df_mtch.HomePTS - df_mtch.AwayPTS)\n",
    "    df_mtch['Total'] = df_mtch.AwayPTS + df_mtch.HomePTS\n",
    "    df_mtch['is_Win'] = np.where(df_mtch.Spread > 0, 1, 0)\n",
    "    df_mtch['Szn_Wins'] = df_mtch.groupby(['Season', 'Team'])['is_Win'].cumsum()\n",
    "    df = df.drop(['Season', 'Team_type'], axis=1).merge(df_mtch, on=['Date', 'Team'])\n",
    "\n",
    "    df = df.merge(df4[['Date', 'Team', 'Player', 'Status']], on=['Date', 'Team', 'Player'], how='left')\n",
    "    df['Status'] = np.where((df.Active == 1) & (df.Status.isnull()), 'Available', df.Status)\n",
    "    df['Status'] = np.where((df.Active == 0), 'Out', df.Status)\n",
    "    df['Status'] = np.where((df.Status == 'Out') & (df.Active != 0), 'Available', df.Status)\n",
    "\n",
    "    df6['role'] = 1\n",
    "    df = df.merge(df6.drop('Pos', axis=1), on=['Season', 'Date', 'Team', 'Player'], how='left')\n",
    "    df['role'] = df.role.fillna(2).astype(int)\n",
    "    df['role'] = np.where(((df.MP < 8) & (df.role == 2)), 3, df.role)\n",
    "\n",
    "    # Add gmlog splits\n",
    "    df_gmlog_comb = df7.merge(df8, on=['game_id', 'Player'])\n",
    "    for df_loop in (df9, df10, df11, df12):\n",
    "        df_gmlog_comb = df_gmlog_comb.merge(df_loop, on=['game_id', 'Player'])\n",
    "    df = df.merge(df_gmlog_comb, on=['game_id', 'Player'], how='left')\n",
    "    \n",
    "    global team_encoder, player_encoder, team_type_encoder, position_encoder, status_encoder\n",
    "    team_encoder = LabelEncoder()\n",
    "    player_encoder = LabelEncoder()\n",
    "    team_type_encoder = LabelEncoder()\n",
    "    position_encoder = LabelEncoder()\n",
    "    status_encoder = LabelEncoder()\n",
    "\n",
    "    # Encode string cols\n",
    "    team_encoder.fit(pd.concat([df[\"Team\"], df[\"Opp\"]], axis=0))\n",
    "    players_fits = pd.concat([df[\"Player\"], df3[\"Player\"]], axis=0)\n",
    "    players_fits = pd.concat([players_fits, df4[\"Player\"]], axis=0).drop_duplicates()\n",
    "    player_encoder.fit(players_fits)\n",
    "    df[\"Team\"] = team_encoder.transform(df[\"Team\"])\n",
    "    df[\"Opp\"] = team_encoder.transform(df[\"Opp\"])\n",
    "    df[\"Player_name\"] = df.Player\n",
    "    df[\"Player\"] = player_encoder.transform(df[\"Player\"])\n",
    "    df[\"Pos\"] = position_encoder.fit_transform(df[\"Pos\"])\n",
    "    df['Team_type'] = team_type_encoder.fit_transform(df['Team_type'])\n",
    "    df[\"Status\"] = status_encoder.fit_transform(df[\"Status\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacb4a82",
   "metadata": {},
   "source": [
    "### Create missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "738bbea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_missing(df, pred_col):\n",
    "    \n",
    "    df3 = load_df('season_gamelogs')\n",
    "    df3 = df3.rename(columns={\"3PM\": \"TPM\", \"3PA\": \"TPA\", \"3P%\": \"TP%\", \"TRB\": \"REB\"}).drop(['Pos', 'Opp'], axis=1)\n",
    "    df3['PR'] = df3.PTS + df3.REB \n",
    "    df3['PA'] = df3.PTS + df3.AST\n",
    "    df3['RA'] = df3.REB + df3.AST\n",
    "    df3['PRA'] = df3.PTS + df3.REB + df3.AST\n",
    "    df3['STL_BLK'] = df3.STL + df3.BLK\n",
    "    df4 = load_df('injuries')\n",
    "    # Fill missing games from injuries.csv\n",
    "    df_pred = create_base_df()\n",
    "    team_games = df_pred[['Season', 'Team', 'Date']].drop_duplicates()\n",
    "    players = df_pred[['Season','Player','Team']].drop_duplicates()\n",
    "    fabricated = (players.sort_values('Season').groupby('Player', as_index=False).last())\n",
    "    fabricated['Season'] = fabricated['Season'] + 1\n",
    "    players = pd.concat([players, fabricated], ignore_index=True).drop_duplicates(['Season','Player','Team'])\n",
    "    expanded = team_games.merge(players, on=['Season', 'Team'], how='left')\n",
    "\n",
    "    df3[\"Team\"] = team_encoder.transform(df3[\"Team\"])\n",
    "    df3[\"Player\"] = player_encoder.transform(df3[\"Player\"])\n",
    "    df4[\"Team\"] = team_encoder.transform(df4[\"Team\"])\n",
    "    df4[\"Player\"] = player_encoder.transform(df4[\"Player\"])\n",
    "    df5 = load_df('plyr_pos_xref')\n",
    "    df5['Team'] = team_encoder.transform(df5[\"Team\"])\n",
    "    df5['Player'] = player_encoder.transform(df5[\"Player\"])\n",
    "\n",
    "    expanded = expanded.merge(df3[['Season', 'Player', 'Date', 'MP']], on=['Season', 'Player', 'Date'], how='left').drop_duplicates(['Season', 'Date', 'Player', 'Team'])\n",
    "    expanded = expanded[(expanded.MP.isnull()) & (expanded.Date != now)].drop('MP', axis=1)\n",
    "    expanded = pd.concat([expanded, df4[df4.Status == 'Out'][['Season', 'Team', 'Date', 'Player']]])\n",
    "    df4 = df4.merge(expanded, on=['Season', 'Date', 'Team', 'Player'], how='right')\n",
    "\n",
    "    # Grab outs from players season gamelogs\n",
    "    df4 = df4.merge(df3, on=['Season', 'Date', 'Team', 'Player'], how='outer')\n",
    "    df4['Status'] = np.where(((df4.Active == 1) | (df4.MP > 0)), 'Available', df4.Status)\n",
    "    df4['Status'] = np.where(((df4.Active == 0) | (df4.MP == 0) | (df4.MP.isnull())), 'Out', df4.Status)\n",
    "    df4['Status'] = np.where((df4.Status == 'Out') & (df4.MP > 0), 'Available', df4.Status)\n",
    "    df4['Status'] = np.where((df4.Status != 'Out') & (df4.MP == 0), 'Out', df4.Status)\n",
    "    df4 = df4[df4.Status == 'Out'][['Season', 'Date', 'Team', 'Player']].drop_duplicates()\n",
    "    \n",
    "    df_missing = df[['Season', 'Date', 'Team', 'Player', 'role', pred_col]].copy()\n",
    "    df_missing[f'{pred_col}_L10'] = (\n",
    "        df_missing.groupby(['Player','Season'])[pred_col]\n",
    "                  .transform(lambda x: x.rolling(10, min_periods=1).mean())\n",
    "    )\n",
    "    df_missing['role_L10_mode'] = (\n",
    "        df_missing\n",
    "            .groupby(['Player', 'Season'])['role']\n",
    "            .transform(lambda x: x.rolling(10, min_periods=1)\n",
    "                            .apply(lambda y: np.bincount(y.astype(np.int8), minlength=4).argmax(), raw=True))\n",
    "    )\n",
    "    df_missing = pd.merge_asof(df4, df_missing[[\"Season\", \"Player\", \"Date\", \"role\", \"role_L10_mode\", f\"{pred_col}_L10\"]], \n",
    "                      on=\"Date\", by=[\"Player\", \"Season\"], direction=\"backward\", allow_exact_matches=True).dropna()   \n",
    "    df_missing = df_missing.merge(df5, on=['Season', 'Team', 'Player'])\n",
    "    \n",
    "    # Filter out old injuries\n",
    "    df_missing = df_missing.sort_values([\"Season\", \"Team\", \"Player\", \"Date\"])\n",
    "    df_missing[\"team_game_num\"] = (df_missing.groupby([\"Season\", \"Team\"])[\"Date\"].rank(method=\"dense\").astype(int))\n",
    "    df_missing[\"game_break\"] = (df_missing.groupby([\"Season\", \"Team\", \"Player\"])[\"team_game_num\"].diff().ne(1))\n",
    "    df_missing[\"streak_id\"] = (df_missing.groupby([\"Season\", \"Team\", \"Player\"])[\"game_break\"].cumsum())\n",
    "    df_missing[\"consecutive_games\"] = (df_missing.groupby([\"Season\", \"Team\", \"Player\", \"streak_id\"]).cumcount().add(1))\n",
    "    df_missing[\"eligible_today\"] = (df_missing[\"consecutive_games\"] < 10).astype(int)\n",
    "    df_missing[\"role_for_count\"] = np.where(df_missing[\"eligible_today\"] == 1, df_missing[\"role_L10_mode\"], np.nan)    \n",
    "\n",
    "    df_missing[\"Player\"] = player_encoder.inverse_transform(df_missing[\"Player\"])\n",
    "#     display(df_missing[df_missing.Team == 7].tail(50))\n",
    "\n",
    "    out_minutes = (\n",
    "    df_missing\n",
    "      .groupby([\"Season\", \"Date\", \"Team\"])\n",
    "      .agg(\n",
    "#           team_mins_available=(\"MP_L10\", lambda x: x.sum()),\n",
    "          starters_out=(\"role_for_count\", lambda x: (x == 1).sum())\n",
    "      )\n",
    "      .reset_index()\n",
    "    )\n",
    "\n",
    "    return out_minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ca73c9",
   "metadata": {},
   "source": [
    "# Minutes Projection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d66b399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_df_mins(con, df):\n",
    "\n",
    "    df = df[['Season', 'Date', 'Team', 'Team_type', 'Opp', 'Player', 'Pos', 'role', 'B2B', \n",
    "             'MP', 'MP_h1', 'MP_h2', 'MP_q1', 'MP_q2', 'MP_q3', 'MP_q4', \n",
    "             'Spread', 'team_game_num', 'pstszn_gm', 'is_OT']]    \n",
    "    df['dataset_gm'] = (df.groupby('Player')['MP'].cumcount().add(1).reset_index(drop=True))\n",
    "\n",
    "    for col in ['MP']:\n",
    "        for N in [3, 5, 10]:\n",
    "            df[f'{col}_L{N}_avg'] = (\n",
    "                df.groupby(['Player', 'Season'])[col]\n",
    "                  .rolling(window=N, min_periods=1)\n",
    "                  .mean()\n",
    "                  .shift(1)\n",
    "                  .reset_index(level=[0, 1], drop=True)\n",
    "            )\n",
    "            df[f'{col}_L{N}_avg'] = np.where(df['dataset_gm'] <= N, np.nan, df[f'{col}_L{N}_avg'])\n",
    "            df[f'prev_team_mins_pct_L{N}'] = df[f'{col}_L{N}_avg'] / 240\n",
    "\n",
    "    games_last_7_days = df.sort_values(['Player', 'Season', 'Date']).groupby(['Player', 'Season']).rolling('7D', on='Date', closed='left')['MP'].count().reset_index().rename(columns={\"MP\": \"gms_L7_days\"})\n",
    "    games_last_7_days = games_last_7_days.drop_duplicates(\n",
    "        subset=['Player', 'Season', 'Date']\n",
    "    )\n",
    "    df = df.merge(games_last_7_days, on=['Player', 'Season', 'Date'])\n",
    "    df['gms_L7_days'] = df.gms_L7_days.fillna(0).astype(int)\n",
    "        \n",
    "    df['OT_adj_MP'] = np.where(df.is_OT != 0, df.MP - (5 * df.is_OT), df.MP)\n",
    "    df['role'] = np.where(((df.OT_adj_MP >= 24) & (df.role != 1)), 1, df.role)\n",
    "    df['role'] = np.where(((df.OT_adj_MP < 24) & (df.role == 1)), 2, df.role)\n",
    "    df['role'] = np.where(((df.OT_adj_MP < 14) & (df.role == 2)), 3, df.role)\n",
    "    for N in [1, 3, 5]:\n",
    "        df[f\"recent_role_L{N}\"] = (\n",
    "            df\n",
    "            .groupby([\"Player\", \"Season\"])[\"role\"]\n",
    "            .rolling(5, min_periods=1)\n",
    "            .apply(lambda arr: np.bincount(arr.astype(int), minlength=4).argmax(), raw=True)\n",
    "            .reset_index(level=[0, 1], drop=True)\n",
    "        )\n",
    "        df[f\"recent_role_L{N}\"] = np.where(df['dataset_gm'] <= N, np.nan, df[f\"recent_role_L{N}\"])     \n",
    "    \n",
    "    df['game_spread_type'] = 0\n",
    "    df['game_spread_type'] = np.where(abs(df.Spread) < 7, 1, df.game_spread_type) \n",
    "    df['game_spread_type'] = np.where((abs(df.Spread) >= 7) & (abs(df.Spread) <= 12), 2, df.game_spread_type) \n",
    "    df['game_spread_type'] = np.where(abs(df.Spread) > 12, 3, df.game_spread_type) \n",
    "    df['game_spread_type'] = np.where(df.is_OT > 0, 1, df.game_spread_type) \n",
    "\n",
    "    # Tell model games exist after players injuries/susp\n",
    "    team_games = df[['Season', 'Team', 'Date', 'team_game_num']].drop_duplicates()\n",
    "    players = df[['Season','Player','Team']].drop_duplicates()\n",
    "    fabricated = (players.sort_values('Season').groupby('Player', as_index=False).last())\n",
    "    fabricated['Season'] = fabricated['Season'] + 1\n",
    "    players = pd.concat([players, fabricated], ignore_index=True).drop_duplicates(['Season','Player','Team'])\n",
    "    expanded = team_games.merge(players, on=['Season', 'Team'], how='left')\n",
    "    expanded = expanded.merge(df[['Season', 'Player', 'Date', 'MP']], on=['Season', 'Player', 'Date'], how='left').drop_duplicates(['Season', 'Date', 'Player', 'Team'])\n",
    "    expanded['player_played'] = expanded['MP'].notna().astype(int)\n",
    "    expanded['team_played_no_player'] = ((expanded['player_played'] == 0)).astype(int)\n",
    "    expanded['tm_plays_after'] = (expanded.groupby(['Player'])['team_played_no_player'].shift(-1))\n",
    "    expanded['missed_gms_aftr'] = 0\n",
    "    expanded['missed_gms_aftr'] = np.where((expanded.player_played == 1) & (expanded.tm_plays_after == 1), 1, expanded.missed_gms_aftr)\n",
    "    df = df.merge(expanded[['Date', 'Team', 'Player', 'missed_gms_aftr']], on=['Date', 'Team', 'Player'])\n",
    "    \n",
    "    df2 = create_df_missing(df, 'MP')\n",
    "    df = df.merge(df2, on=[\"Season\", \"Date\", \"Team\"], how='left')\n",
    "    df['starters_out'] = df.starters_out.fillna(0)\n",
    "    df['starters_out_L1'] = (\n",
    "        df.groupby(['Player', 'Season'])['starters_out']\n",
    "          .rolling(window=1, min_periods=1)\n",
    "          .mean()\n",
    "          .shift(1)\n",
    "          .reset_index(level=[0, 1], drop=True)\n",
    "    )\n",
    "    df['starters_returning'] = np.where(df['starters_out_L1'] > df['starters_out'], df['starters_out_L1'] - df['starters_out'], 0)\n",
    "    df['missed_games'] = (df.groupby(['Player', 'Team', 'Season'])['team_game_num'].diff().sub(1).fillna(0).astype(int))\n",
    "\n",
    "    df['MP_Change'] = 0\n",
    "    MP_Inc_conds = (\n",
    "                    ((df.role != 3) & (df.starters_out > 2)) | \n",
    "                    ((df.role == 1) & (df.recent_role_L3 > 1)) | \n",
    "                    ((df.role == 1) & (df.recent_role_L5 > 1)) \n",
    "                   )\n",
    "    df['MP_Change'] = np.where(MP_Inc_conds, 1, df['MP_Change'])\n",
    "    MP_Dec_conds = (\n",
    "                    ((df.role != 1) & (df.starters_returning > 2)) \n",
    "                   )\n",
    "    df['MP_Change'] = np.where(MP_Dec_conds, -1, df['MP_Change'])\n",
    "    \n",
    "    df['MP_change_pct_L10'] = (df['MP'] - df['MP_L10_avg']) / df['MP_L10_avg']\n",
    "    Injury_conds = (\n",
    "        (\n",
    "            ((df.role == 1) & (df['MP_change_pct_L10'] <= -0.25)) | \n",
    "            ((df.role == 2) & (df['MP_change_pct_L10'] <= -0.35)) | \n",
    "            ((df.role == 3) & (df['MP_change_pct_L10'] <= -0.45)) | \n",
    "            ((df.role == 1) & (df.MP_q4 == 0)\n",
    "        ) & (df.missed_gms_aftr > 0) | (df.missed_games > 1))\n",
    "    )\n",
    "    df['Injured'] = (Injury_conds).astype(int)\n",
    "    df['return_game'] = ((df.groupby('Player')['Injured'].shift(1) == 1) & (df.missed_games > 0)).astype(int)\n",
    "    df['games_since_return'] = (df.groupby('Player')['return_game'].cumsum())\n",
    "    df['games_since_return'] = (df.groupby(['Player', 'games_since_return']).cumcount())\n",
    "    df['ramp_phase'] = 0\n",
    "    df.loc[df.return_game == 1, 'ramp_phase'] = 1\n",
    "    df.loc[(df.games_since_return.isin([1, 2, 3]) & (df.dataset_gm > 4)), 'ramp_phase'] = 2\n",
    "    df.loc[df.games_since_return >= 4, 'ramp_phase'] = 0\n",
    "\n",
    "    df = df.drop(['Season', 'Team_type', 'team_game_num', 'Spread', 'is_OT', 'starters_out_L1', \n",
    "                  'MP_h1', 'MP_h2', 'MP_q1', 'MP_q2', 'MP_q3', 'MP_q4', 'OT_adj_MP', 'MP_change_pct_L10',   \n",
    "                  'missed_gms_aftr', 'Injured', 'return_game', 'games_since_return', 'dataset_gm'], axis=1)      \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c246f0c",
   "metadata": {},
   "source": [
    "# Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4d1ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_df_main(df, tgt_stat):\n",
    "    \n",
    "    df = df[['Season', 'Date', 'Team', 'Opp', 'Player', 'Pos', 'role', 'MP', 'team_game_num', \n",
    "             'PTS', 'FG', 'FGA', 'FG%', 'TPA', 'TPM', 'TP%', 'FT', 'FTA', 'FT%', \n",
    "             'MP_h1', 'MP_h2', 'MP_q1', 'MP_q2', 'MP_q3', 'MP_q4', \n",
    "             f'Off_{tgt_stat}', f'Off_L3_{tgt_stat}', f'Off_L5_{tgt_stat}', f'Off_L10_{tgt_stat}', f'Off_{tgt_stat}_Rk',\n",
    "             f'Def_{tgt_stat}', f'Def_L3_{tgt_stat}', f'Def_L5_{tgt_stat}', f'Def_L10_{tgt_stat}', f'Def_{tgt_stat}_Rk',\n",
    "             'Spread', 'Total', 'is_OT']]\n",
    "    df['dataset_gm'] = (df.groupby('Player')['MP'].cumcount().add(1).reset_index(drop=True))\n",
    "    \n",
    "    # Create rolling + lag features    \n",
    "    for col in ['MP', 'FG', 'FGA', 'FT', 'FTA', 'TPM', 'TPA']:\n",
    "        for N in [3, 5, 10]:\n",
    "            df[f'{col}_L{N}_avg'] = (\n",
    "                df.groupby(['Player', 'Season'])[col]\n",
    "                  .rolling(window=N, min_periods=1)\n",
    "                  .mean()\n",
    "                  .shift(1)\n",
    "                  .reset_index(level=[0, 1], drop=True)\n",
    "            )\n",
    "            \n",
    "    for N in [1, 3, 5]:\n",
    "        df[f\"recent_role_L{N}\"] = (\n",
    "            df\n",
    "            .groupby([\"Player\", \"Season\"])[\"role\"]\n",
    "            .rolling(5, min_periods=1)\n",
    "            .apply(lambda arr: np.bincount(arr.astype(int), minlength=4).argmax(), raw=True)\n",
    "            .reset_index(level=[0, 1], drop=True)\n",
    "        )\n",
    "\n",
    "    df['OT_adj_MP'] = np.where(df.is_OT != 0, df.MP - (5 * df.is_OT), df.MP)\n",
    "    df['role'] = np.where(((df.OT_adj_MP >= 24) & (df.role != 1)), 1, df.role)\n",
    "    df['role'] = np.where(((df.OT_adj_MP < 24) & (df.role == 1)), 2, df.role)\n",
    "    df['role'] = np.where(((df.OT_adj_MP < 14) & (df.role == 2)), 3, df.role)\n",
    "    for N in [1, 3, 5]:\n",
    "        df[f\"recent_role_L{N}\"] = (\n",
    "            df\n",
    "            .groupby([\"Player\", \"Season\"])[\"role\"]\n",
    "            .rolling(5, min_periods=1)\n",
    "            .apply(lambda arr: np.bincount(arr.astype(int), minlength=4).argmax(), raw=True)\n",
    "            .reset_index(level=[0, 1], drop=True)\n",
    "        )\n",
    "    \n",
    "    df['game_spread_type'] = 0\n",
    "    df['game_spread_type'] = np.where(abs(df.Spread) < 7, 1, df.game_spread_type) \n",
    "    df['game_spread_type'] = np.where((abs(df.Spread) >= 7) & (abs(df.Spread) <= 12), 2, df.game_spread_type) \n",
    "    df['game_spread_type'] = np.where(abs(df.Spread) > 12, 3, df.game_spread_type) \n",
    "    df['game_spread_type'] = np.where(df.is_OT > 0, 1, df.game_spread_type) \n",
    "    \n",
    "    df['TeamPTS'] = (df.Total + (df.Spread * -1)) / 2\n",
    "    df['TeamPTS_type'] = 0\n",
    "    df['TeamPTS_type'] = np.where((df.TeamPTS > 104) & (df.TeamPTS <= 116), 1, df.TeamPTS_type)\n",
    "    df['TeamPTS_type'] = np.where((df.TeamPTS > 116) & (df.TeamPTS <= 126), 2, df.TeamPTS_type)\n",
    "    df['TeamPTS_type'] = np.where((df.TeamPTS > 126), 3, df.TeamPTS_type)\n",
    "    \n",
    "    # Tell model games exist after players injuries/susp\n",
    "    team_games = df[['Season', 'Team', 'Date', 'team_game_num']].drop_duplicates()\n",
    "    players = df[['Season','Player','Team']].drop_duplicates()\n",
    "    fabricated = (players.sort_values('Season').groupby('Player', as_index=False).last())\n",
    "    fabricated['Season'] = fabricated['Season'] + 1\n",
    "    players = pd.concat([players, fabricated], ignore_index=True).drop_duplicates(['Season','Player','Team'])\n",
    "    expanded = team_games.merge(players, on=['Season', 'Team'], how='left')\n",
    "    expanded = expanded.merge(df[['Season', 'Player', 'Date', 'MP']], on=['Season', 'Player', 'Date'], how='left').drop_duplicates(['Season', 'Date', 'Player', 'Team'])\n",
    "    expanded['player_played'] = expanded['MP'].notna().astype(int)\n",
    "    expanded['team_played_no_player'] = ((expanded['player_played'] == 0)).astype(int)\n",
    "    expanded['tm_plays_after'] = (expanded.groupby(['Player'])['team_played_no_player'].shift(-1))\n",
    "    expanded['missed_gms_aftr'] = 0\n",
    "    expanded['missed_gms_aftr'] = np.where((expanded.player_played == 1) & (expanded.tm_plays_after == 1), 1, expanded.missed_gms_aftr)\n",
    "    df = df.merge(expanded[['Date', 'Team', 'Player', 'missed_gms_aftr']], on=['Date', 'Team', 'Player'])\n",
    "    \n",
    "    df2 = create_df_missing(df, 'MP')\n",
    "    df = df.merge(df2, on=[\"Season\", \"Date\", \"Team\"], how='left')\n",
    "    df['starters_out'] = df.starters_out.fillna(0)\n",
    "    df['starters_out_L1'] = (\n",
    "        df.groupby(['Player', 'Season'])['starters_out']\n",
    "          .rolling(window=1, min_periods=1)\n",
    "          .mean()\n",
    "          .shift(1)\n",
    "          .reset_index(level=[0, 1], drop=True)\n",
    "    )\n",
    "    df['starters_returning'] = np.where(df['starters_out_L1'] > df['starters_out'], df['starters_out_L1'] - df['starters_out'], 0)\n",
    "    df['missed_games'] = (df.groupby(['Player', 'Team', 'Season'])['team_game_num'].diff().sub(1).fillna(0).astype(int))\n",
    "\n",
    "    df['MP_Change'] = 0\n",
    "    MP_Inc_conds = (\n",
    "                    ((df.role != 3) & (df.starters_out > 2)) | \n",
    "                    ((df.role == 1) & (df.recent_role_L3 > 1)) | \n",
    "                    ((df.role == 1) & (df.recent_role_L5 > 1)) \n",
    "                   )\n",
    "    df['MP_Change'] = np.where(MP_Inc_conds, 1, df['MP_Change'])\n",
    "    MP_Dec_conds = (\n",
    "                    ((df.role != 1) & (df.starters_returning > 2)) \n",
    "                   )\n",
    "    df['MP_Change'] = np.where(MP_Dec_conds, -1, df['MP_Change'])\n",
    "    \n",
    "    df['MP_change_pct_L10'] = (df['MP'] - df['MP_L10_avg']) / df['MP_L10_avg']\n",
    "    Injury_conds = (\n",
    "        (\n",
    "            ((df.role == 1) & (df['MP_change_pct_L10'] <= -0.25)) | \n",
    "            ((df.role == 2) & (df['MP_change_pct_L10'] <= -0.35)) | \n",
    "            ((df.role == 3) & (df['MP_change_pct_L10'] <= -0.45)) | \n",
    "            ((df.role == 1) & (df.MP_q4 == 0)\n",
    "        ) & (df.missed_gms_aftr > 0) | (df.missed_games > 1))\n",
    "    )\n",
    "    df['Injured'] = (Injury_conds).astype(int)\n",
    "    df['return_game'] = ((df.groupby('Player')['Injured'].shift(1) == 1) & (df.missed_games > 0)).astype(int)\n",
    "    df['games_since_return'] = (df.groupby('Player')['return_game'].cumsum())\n",
    "    df['games_since_return'] = (df.groupby(['Player', 'games_since_return']).cumcount())\n",
    "    df['ramp_phase'] = 0\n",
    "    df.loc[df.return_game == 1, 'ramp_phase'] = 1\n",
    "    df.loc[(df.games_since_return.isin([1, 2, 3]) & (df.dataset_gm > 4)), 'ramp_phase'] = 2\n",
    "    df.loc[df.games_since_return >= 4, 'ramp_phase'] = 0\n",
    "    \n",
    "    df = df.drop(['Season', 'team_game_num', 'is_OT', 'Spread', 'Total', 'TeamPTS', \n",
    "                 'FG', 'FGA', 'FG%', 'TPA', 'TPM', 'TP%', 'FT', 'FTA', 'FT%', \n",
    "                 'MP_h1', 'MP_h2', 'MP_q1', 'MP_q2', 'MP_q3', 'MP_q4', \n",
    "                 'OT_adj_MP', 'MP_change_pct_L10', 'starters_out_L1', \n",
    "                 'missed_gms_aftr', 'Injured', 'return_game', 'games_since_return', 'dataset_gm'], axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e692b2b",
   "metadata": {},
   "source": [
    "### Today's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99caad3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_predictions(tgt_stat):\n",
    "    \n",
    "    df_pred = create_base_df()\n",
    "        \n",
    "    mins_model = xgb.XGBRegressor()\n",
    "    mins_model.load_model(\"../ML_models/mins_model.json\")\n",
    "    stat_model = xgb.XGBRegressor()\n",
    "    stat_model.load_model(f\"../ML_models/{tgt_stat}_model.json\")\n",
    "    \n",
    "    df_lines = pd.read_csv(f\"../tables/2025/parlay_lines.csv\")\n",
    "    df_lines['Date'] = pd.to_datetime(df_lines.Date)\n",
    "    df_lines = df_lines[~(df_lines.Team.isnull())]\n",
    "\n",
    "    # Predict Mins\n",
    "    df_lines[\"Team\"] = team_encoder.transform(df_lines[\"Team\"])\n",
    "    df_pred = df_pred.merge(df_lines[['Date', 'Team', 'Spread', 'Total']], on=['Date', 'Team'], how='left')\n",
    "    df_pred = df_pred[~df_pred[['Date', 'Team', 'Player']].duplicated(keep='last')]\n",
    "    df_pred['Spread_x'] = np.where(df_pred.Spread_x.isnull(), df_pred.Spread_y, df_pred.Spread_x)\n",
    "    df_pred['Total_x'] = np.where(df_pred.Total_x.isnull(), df_pred.Total_y, df_pred.Total_x)\n",
    "    df_pred = df_pred.rename(columns={\"Spread_x\": \"Spread\", \"Total_x\": \"Total\"}).drop(['Spread_y', 'Total_y'], axis=1)\n",
    "    df_pred_mins = setup_df_mins(con, df_pred)\n",
    "    \n",
    "#     # debug mins preds\n",
    "#     mins_chk = df_pred_mins[df_pred_mins.Date == now]\n",
    "#     mins_chk['Team'] = team_encoder.inverse_transform(mins_chk[\"Team\"])\n",
    "#     mins_chk['Player'] = player_encoder.inverse_transform(mins_chk[\"Player\"])\n",
    "#     if mins_chk.shape[0] >= 50:\n",
    "#         for tm in mins_chk.Team.unique():\n",
    "#             display(mins_chk[mins_chk.Team == tm])\n",
    "#     else:\n",
    "#         display(mins_chk)\n",
    "    \n",
    "    df_pred_mins = df_pred_mins.drop(['Date', 'MP'], axis=1)\n",
    "    df_pred['MP'] = mins_model.predict(df_pred_mins)\n",
    "\n",
    "    # Predict Stat\n",
    "    df_pred = setup_df_main(df_pred, tgt_stat)\n",
    "    feature_cols = [col for col in df_pred.columns if col not in ['Date', tgt_stat]]\n",
    "    df_pred = df_pred[df_pred.Date == now][feature_cols]\n",
    "    df_pred[f\"{tgt_stat}_proj\"] = stat_model.predict(df_pred)\n",
    "\n",
    "    # Setup results\n",
    "    df_pred['Team'] = team_encoder.inverse_transform(df_pred[\"Team\"])\n",
    "    df_lines['Team'] = team_encoder.inverse_transform(df_lines[\"Team\"])\n",
    "    df_pred['Opp'] = team_encoder.inverse_transform(df_pred[\"Opp\"])\n",
    "    df_pred['Player'] = player_encoder.inverse_transform(df_pred[\"Player\"])\n",
    "    df_pred['Pos'] = position_encoder.inverse_transform(df_pred[\"Pos\"])\n",
    "\n",
    "    df_lines = df_lines[df_lines.Date == now][['Team', 'Player', f'{tgt_stat}_line']]\n",
    "    df_pred = df_pred.merge(df_lines, on=['Team', 'Player'])\n",
    "    df_pred = df_pred[~(df_pred[f'{tgt_stat}_line'].isnull())]\n",
    "    df_pred['Diff'] = abs((df_pred[f'{tgt_stat}_line'] - df_pred[f'{tgt_stat}_proj']))\n",
    "    df_pred['Diff2'] = abs((df_pred['MP'] - df_pred['MP_L5_avg']))\n",
    "    df_pred = df_pred.sort_values('Diff', ascending=False).drop(['Diff', 'Diff2'], axis=1)\n",
    "\n",
    "#     # debug stat preds\n",
    "#     if df_pred.shape[0] >= 50:\n",
    "#         print(df_pred.shape[0], 'rows')\n",
    "#         for tm in df_pred.Team.unique():\n",
    "#             display(df_pred[df_pred.Team == tm])\n",
    "#     else:\n",
    "#         display(df_pred)\n",
    "\n",
    "    tds_picks = df_pred[['Team', 'Player', 'Pos', 'Opp', 'MP', 'MP_L5_avg', 'game_spread_type', f'{tgt_stat}_line', f'{tgt_stat}_proj']]\n",
    "    if tds_picks.shape[0] >= 50:\n",
    "        print(tds_picks.shape[0], 'rows')\n",
    "        for tm in tds_picks.Team.unique():\n",
    "            display(tds_picks[tds_picks.Team == tm])\n",
    "    else:\n",
    "        display(tds_picks)\n",
    "    tds_picks.insert(0, 'Date', pd.to_datetime(now))\n",
    "    partition_save_df(tds_picks, f\"../tables/2025/gmday_preds_{tgt_stat}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f107f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    generate_predictions('PTS')\n",
    "except Exception as e:\n",
    "    email('PTS', e)\n",
    "    raise Exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fcb793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fantasy2",
   "language": "python",
   "name": "fantasy2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
